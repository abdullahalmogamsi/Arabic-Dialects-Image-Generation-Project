# -*- coding: utf-8 -*-
"""Final_AltDiffusion_Model_Image_Generation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Lw2L0hybwTr5fPUpTOzis_6tBPJLxMtZ

## **Get the Alt Diffusion Model from Huggingface**
"""

# !pip install git+https://github.com/huggingface/diffusers.git torch transformers sentencepiece
!pip install diffusers==0.24.0 torch transformers sentencepiece

#connect to drive

from google.colab import drive
drive.mount('/content/drive')

from diffusers import AltDiffusionPipeline, DPMSolverMultistepScheduler
import torch

if torch.cuda.is_available():
  pipe = AltDiffusionPipeline.from_pretrained("BAAI/AltDiffusion-m9", torch_dtype=torch.float16)
  pipe = pipe.to("cuda")

else:
  pipe = AltDiffusionPipeline.from_pretrained("BAAI/AltDiffusion-m9")
pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)

"""### Test the Model"""

prompt =  "بنت لابسه جاكيت احمر"
# or in English:
#prompt =  "girl wearing a red jacket"
# prompt = "dark elf princess, highly detailed, d & d, fantasy, highly detailed, digital painting, trending on artstation, concept art, sharp focus, illustration, art by artgerm and greg rutkowski and fuji choko and viktoria gavrilenko and hoang lap"
image = pipe(prompt, num_inference_steps=25).images[0]
image.save("./3.png")

"""### **Getting the Data**"""

!gdown 1G-OBSp5s0NKR2HwnpXcI52Gv1rNcZGcC



"""## **Generating images Function and data**"""

!kaggle datasets download -d adityajn105/flickr8k
!unzip /content/flickr8k.zip

!unzip /content/transformer_dialects_data.zip

# download longest_captions_lable for 1500 samples
!gdown 1xwoKclfvbkDyHBbLaMOGKCF1yQrM-Q6A

import pandas as pd
original_data = pd.read_csv('/content/drive/MyDrive/Final V Project 283/project Draft/longest_captions_dataset -1500 samples.csv')

import pandas as pd
original_data = pd.read_csv('/content/longest_captions_dataset -1500 samples.csv')

df_egyptain = pd.read_csv('cleaned_egyptain_dialect_data.csv')
df_egyptian_model_1 = pd.read_csv('egyptian_data_transformed_model_1.csv')
df_egyptian_model_2 = pd.read_csv('egyptian_data_transformed_model_2.csv')
df_egyptian_model_3 = pd.read_csv('egyptian_data_transformed_model_3.csv')

df_khaleeji = pd.read_csv('cleaned_khaleeji_dialect_data.csv')
df_khaleji_model_1 = pd.read_csv('khaleji_data_transformed_model_1.csv')
df_khaleji_model_2 = pd.read_csv('khaleji_data_transformed_model_2.csv')
df_khaleji_model_3 = pd.read_csv('khaleji_data_transformed_model_3.csv')

df_saudi = pd.read_csv('saudi_arabia_dialect_after_cleaning.csv')
df_saudi_model_1 = pd.read_csv('saudi_data_transformed_model_1.csv')
df_saudi_model_2 = pd.read_csv('saudi_data_transformed_model_2.csv')
df_saudi_model_3 = pd.read_csv('saudi_data_transformed_model_3.csv')

df_morrocon = pd.read_csv('morrocon_dialect_after_cleaning.csv')
df_morrocon_model_1 = pd.read_csv('morrocon_data_transformed_model_1.csv')
df_morrocon_model_2 = pd.read_csv('morrocon_data_transformed_model_2.csv')
df_morrocon_model_3 = pd.read_csv('morrocon_data_transformed_model_3.csv')

#df_egyptian_model_1.head()
df_khaleeji.tail()

original_data.drop(original_data.tail(1).index,inplace=True) # drop last n rows
df_egyptain.drop(df_egyptain.tail(2).index,inplace=True) # drop last n rows
df_khaleeji.drop(df_khaleeji.tail(1).index,inplace=True) # drop last n rows
df_morrocon.drop(df_morrocon.tail(1).index,inplace=True) # drop last n rows

print("df_cleaned_egyptain shape:", df_egyptain.shape)
print("df_cleaned_khaleeji shape:", df_khaleeji.shape)
print("df_egyptian_model_1 shape:", df_egyptian_model_1.shape)
print("df_egyptian_model_2 shape:", df_egyptian_model_2.shape)
print("df_egyptian_model_3 shape:", df_egyptian_model_3.shape)
print("df_khaleji_model_1 shape:", df_khaleji_model_1.shape)
print("df_khaleji_model_2 shape:", df_khaleji_model_2.shape)
print("df_khaleji_model_3 shape:", df_khaleji_model_3.shape)
print("df_saudi_cleaned shape:", df_saudi.shape)
print("df_saudi_model_1 shape:", df_saudi_model_1.shape)
print("df_saudi_model_2 shape:", df_saudi_model_2.shape)
print("df_saudi_model_3 shape:", df_saudi_model_3.shape)
print("df_morrocon_model_1 shape:", df_morrocon_model_1.shape)
print("df_morrocon_model_2 shape:", df_morrocon_model_2.shape)
print("df_morrocon_model_3 shape:", df_morrocon_model_3.shape)
print("df_morrocon_cleaned shape:", df_morrocon.shape)

import os
from PIL import Image
def generate_images(captions,images_values,output_dir,df_name):
    os.makedirs(output_dir, exist_ok=True)

    for i, caption in enumerate(captions):
          image = pipe(caption, num_inference_steps=25).images[0]
          image_name = image_values[i][:-4] + df_name
          image.save(os.path.join(output_dir, image_name))

original_data

image_values=original_data['Image_ID'].tolist()



"""#### **Read Gemini Data**"""

image_values=original_data['Image_ID'].tolist()

import pandas as pd
egyptain_english_gemini= pd.read_csv('/content/drive/MyDrive/Final V Project 283/Text_transformer_dialects_data/egyptain_english_gemini.csv')
egyptain_msa_gemini= pd.read_csv('/content/drive/MyDrive/Final V Project 283/Text_transformer_dialects_data/egyptain_msa_gemini.csv')
khaleji_english_gemini= pd.read_csv('/content/drive/MyDrive/Final V Project 283/Text_transformer_dialects_data/khaleji_english_gemini.csv')
khaleji_msa_gemini= pd.read_csv('/content/drive/MyDrive/Final V Project 283/Text_transformer_dialects_data/khaleji_msa_gemini.csv')
saudi_arabia_english_gemini= pd.read_csv('/content/drive/MyDrive/Final V Project 283/Text_transformer_dialects_data/saudi_arabia_english_gemini.csv')
saudi_arabia_msa_gemini= pd.read_csv('/content/drive/MyDrive/Final V Project 283/Text_transformer_dialects_data/saudi_arabia_msa_gemini.csv')
moroccan_english_gemini= pd.read_csv('/content/drive/MyDrive/Final V Project 283/Text_transformer_dialects_data/moroccan_english_gemini.csv')
moroccan_msa_gemini= pd.read_csv('/content/drive/MyDrive/Final V Project 283/Text_transformer_dialects_data/moroccan_msa_gemini.csv')

saudi_arabia_msa_gemini.head()

"""## **saudi arabia images generation**

### **saudi arabia original**
"""

khaleeji_saudi_captions = df_saudi['Khaleeji'].tolist()

output_dir = "/content/drive/MyDrive/saudi_generated_images/generated_saudi_images_original"
generate_images(khaleeji_saudi_captions, image_values, output_dir, "gen_kha_saudi.jpg")

"""### **saudi arabia model 1**"""

df_saudi_model_1.head()

saudi_model1_captions = df_saudi_model_1['transformed_text'].tolist()

len(saudi_model1_captions)

import time
start_time = time.time()

output_dir = "/content/drive/MyDrive/saudi_generated_images/generated_saudi_images_model1"
generate_images(saudi_model1_captions, image_values, output_dir, "gen_kha_saudi_1.jpg")


end_time = time.time()
execution_time = end_time - start_time
print("Execution time:", execution_time, "seconds")

"""### **saudi arabia model 2**"""

saudi_model2_captions = df_saudi_model_2['transformed_text'].tolist()

len(saudi_model2_captions)

output_dir = "/content/drive/MyDrive/saudi_generated_images/generated_saudi_images_model2"
generate_images(saudi_model2_captions, image_values, output_dir, "gen_kha_saudi_2.jpg")

"""### **saudi arabia model 3**"""

saudi_model3_captions = df_saudi_model_3['transformed_text'].tolist()

len(saudi_model3_captions)

output_dir = "/content/drive/MyDrive/saudi_generated_images/generated_saudi_images_model3"
generate_images(saudi_model3_captions, image_values, output_dir, "gen_kha_saudi_3.jpg")

"""### **saudi Transformation Gemini MSA**"""

saudi_arabia_msa_gemini_captions = saudi_arabia_msa_gemini['transformed_text'].tolist()
output_dir = "/content/drive/MyDrive/arabic dialects project faisal/Alt Diffusion Generated Images/generated_saudi_arabia_msa_gemini_images"
generate_images(saudi_arabia_msa_gemini_captions, image_values, output_dir, "gen_kha_saudi_gemini.jpg")

"""### **saudi Transformation Gemini Engish**"""

saudi_arabia_english_gemini_captions = saudi_arabia_english_gemini['transformed_text'].tolist()
output_dir = "/content/drive/MyDrive/arabic dialects project faisal/Alt Diffusion Generated Images/generated_saudi_arabia_english_gemini_images"
generate_images(saudi_arabia_english_gemini_captions, image_values, output_dir, "gen_kha_saudi_gemini_eng.jpg")

"""## **Egyptain Images Generation**"""

df_egyptain.head()

egyptian_captions = df_egyptain['Egyptian'].tolist()

len(egyptian_captions)

#!cd "generated_egyptain_images"
#!mkdir "generated_egyptain_images_original"
#!mkdir "generated_egyptain_images_model1"
!mkdir "generated_egyptain_images_model2"
!mkdir "generated_egyptain_images_model3"
!mkdir "generated_egyptain_images_model4_ar"
#!mkdir "generated_egyptain_images_model4_en"

output_dir = "/kaggle/working/generated_egyptain_images/generated_egyptain_images_original"

generate_images(egyptian_captions,image_values, output_dir,"gen_egy.jpg")

"""### **Egyptain transformation Model 1**"""

df_egyptian_model_1.head()

egyptian_model1_captions = df_egyptian_model_1['transformed_text'].tolist()

len(egyptian_model1_captions)

output_dir = "/kaggle/working/generated_egyptain_images_model1"

generate_images(egyptian_model1_captions,image_values, output_dir,"gen_egy_1.jpg")

# !zip "/kaggle/working/generated_egyptain_images/generated_egyptain_images_original"
import shutil
shutil.make_archive("/kaggle/working/generated_egyptain_images_model1", 'zip', "/kaggle/working/generated_egyptain_images_model1")

from IPython.display import FileLink
FileLink(r'generated_egyptain_images/generated_egyptain_images_original.zip.zip')

"""### **Egyptain transformation Model 2**"""

egyptian_model2_captions = df_egyptian_model_2['transformed_text'].tolist()

len(egyptian_model2_captions)

output_dir = "/kaggle/working/generated_egyptain_images_model2"

generate_images(egyptian_model2_captions,image_values, output_dir,"gen_egy_2.jpg")

"""### **Egyptain transformation Model 3**"""

egyptian_model3_captions = df_egyptian_model_3['transformed_text'].tolist()

len(egyptian_model3_captions)

output_dir = "/kaggle/working/generated_egyptain_images_model3"
generate_images(egyptian_model3_captions,image_values, output_dir)

"""### **Egyptain transformation Gemini MSA**"""

egyptain_msa_gemini_captions = egyptain_msa_gemini['transformed_text'].tolist()
output_dir = "/content/drive/MyDrive/arabic dialects project faisal/Alt Diffusion Generated Images/generated_egyptain_msa_gemini_images"
generate_images(egyptain_msa_gemini_captions, image_values, output_dir, "gen_egy_gemini.jpg")

"""### **Egyptain transformation Gemini English**"""

#egyptain_english_gemini_captions = egyptain_english_gemini['transformed_text'].tolist()
#output_dir = "/content/drive/MyDrive/arabic dialects project faisal/Alt Diffusion Generated Images/generated_egyptain_english_gemini_images"
#generate_images(egyptain_english_gemini_captions, image_values, output_dir, "gen_egy_gemini_eng.jpg")

"""## **Moroccan Images Generation**"""

df_morrocon.head()

morrocon_captions = df_morrocon['Morrocon'].tolist()

len(morrocon_captions)

output_dir = "/content/drive/MyDrive/morrocon_generated_images/generated_morrocon_images_original"
generate_images(morrocon_captions,image_values, output_dir,"gen_mor.jpg")

"""### **Moroccan transformation Model 1**

"""

df_morrocon_model_1.head()

morrocon_model1_captions = df_morrocon_model_1['transformed_text'].tolist()

len(morrocon_model1_captions)

output_dir = "/content/drive/MyDrive/morrocon_generated_images/generated_morrocon_images_model1"
generate_images(morrocon_model1_captions,image_values, output_dir,"gen_mor_1.jpg")

"""### **Moroccan transformation Model 2**"""

morrocon_model2_captions = df_morrocon_model_2['transformed_text'].tolist()

len(morrocon_model2_captions)

output_dir = "/content/drive/MyDrive/morrocon_generated_images/generated_morrocon_images_model2"
generate_images(morrocon_model2_captions,image_values, output_dir,"gen_mor_2.jpg")

"""### **Moroccan transformation Model 3**

"""

morrocon_model3_captions = df_morrocon_model_3['transformed_text'].tolist()

len(morrocon_model3_captions)

output_dir = "/content/drive/MyDrive/morrocon_generated_images/generated_morrocon_images_model3"
generate_images(morrocon_model3_captions,image_values, output_dir,"gen_mor_3.jpg")

"""### **Morrocon transformation Gemini MSA**"""

moroccan_msa_gemini_captions = moroccan_msa_gemini['transformed_text'].tolist()
output_dir = "/content/drive/MyDrive/arabic dialects project faisal/Alt Diffusion Generated Images/generated_moroccan_msa_gemini_images"
generate_images(moroccan_msa_gemini_captions, image_values, output_dir, "gen_mor_gemini.jpg")

"""### **Morrocon transformation Gemini English**"""

moroccan_english_gemini_captions = moroccan_english_gemini['transformed_text'].tolist()
output_dir = "/content/drive/MyDrive/arabic dialects project faisal/Alt Diffusion Generated Images/generated_moroccan_english_gemini_images"
generate_images(moroccan_english_gemini_captions, image_values, output_dir, "gen_mor_gemini_eng.jpg")

"""## **Khaleji Images Generation**

"""

df_khaleeji.head()

khaleeji_captions = df_khaleeji['Khaleeji'].tolist()

len(khaleeji_captions)

image_values

import time
start_time = time.time()
output_dir = "/content/drive/MyDrive/khaleeji_generated_images/generated_khaleeji_images_original"
generate_images(khaleeji_captions, image_values, output_dir, "gen_kha.jpg")

end_time = time.time()
execution_time = end_time - start_time
print("Execution time:", execution_time, "seconds")

"""### **Khaleji transformation Model 1**"""

df_khaleji_model_1.head()

khaleeji_model1_captions = df_khaleji_model_1['transformed_text'].tolist()

len(khaleeji_model1_captions)

import time
start_time = time.time()

output_dir = "/content/drive/MyDrive/khaleeji_generated_images/generated_khaleeji_images_model1"
generate_images(khaleeji_model1_captions, image_values, output_dir, "gen_kha_1.jpg")


end_time = time.time()
execution_time = end_time - start_time
print("Execution time:", execution_time, "seconds")

"""### **Khaleji transformation Model 2**

"""

khaleeji_model2_captions = df_khaleji_model_2['transformed_text'].tolist()

output_dir = "/content/drive/MyDrive/khaleeji_generated_images/generated_khaleeji_images_model3"
generate_images(khaleeji_model2_captions, image_values, output_dir, "gen_kha_2.jpg")

"""### **Khaleji transformation Model 3**"""

khaleeji_model3_captions = df_khaleji_model_3['transformed_text'].tolist()

len(khaleeji_model3_captions)

output_dir = "/content/drive/MyDrive/khaleeji_generated_images/generated_khaleeji_images_model3"
generate_images(khaleeji_model3_captions, image_values, output_dir, "gen_kha_3.jpg")

"""### **khaleji transformation Gemini MSA**"""

khaleji_msa_gemini_captions = khaleji_msa_gemini['transformed_text'].tolist()
output_dir = "/content/drive/MyDrive/arabic dialects project faisal/Alt Diffusion Generated Images/generated_khaleji_msa_gemini_images.csv"
generate_images(khaleji_msa_gemini_captions, image_values, output_dir, "gen_kha_gemini.jpg")

"""### **khaleji transformation Gemini English**"""



khaleji_english_gemini_captions = khaleji_msa_gemini['transformed_text'].tolist()
output_dir = "/content/drive/MyDrive/arabic dialects project faisal/Alt Diffusion Generated Images/generated_khaleji_english_gemini_images.csv'"
generate_images(khaleji_english_gemini_captions, image_values, output_dir, "gen_kha_gemini_eng.jpg")

"""## stop NotBook"""

# disconnect the session and terminal

# Assuming you want to disconnect the current Colab session.
from google.colab import runtime
runtime.unassign()